{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SYSC4906_Assig2_Template.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuXZ7kBp8kp5",
        "colab_type": "text"
      },
      "source": [
        "# SYSC4906 Assignment 2\n",
        "\n",
        "**Name:** \n",
        "\n",
        "**Student number:** \n",
        "\n",
        "Portions of this template are based on notebook by Jorge Rodríguez Araújo\n",
        "\n",
        "    https://medium.com/abraia/first-steps-with-transfer-learning-for-custom-image-classification-with-keras-b941601fcad5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n6M_ws2dwHR",
        "colab_type": "text"
      },
      "source": [
        "# Step 1: Load the image dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QczBezAN8cgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%capture\n",
        "from glob import glob\n",
        "\n",
        "# Load data from SYSC4906 GitHub repo:\n",
        "!wget https://github.com/jrgreen7/SYSC4906/blob/master/Assignments/Assignment2/SYSC4906_Assig2_Data.zip?raw=true\n",
        "!unzip SYSC4906_Assig2_Data.zip?raw=true\n",
        "\n",
        "# Get list of filenames for the four datasets:\n",
        "TRAIN_DIR = 'train'\n",
        "TEST_DIR = 'test'\n",
        "trump_train = glob('train/trump/*.jpeg')\n",
        "trump_test = glob('test/trump/*.jpeg')\n",
        "decoy_train = glob('train/decoy/*.jpeg')\n",
        "decoy_test = glob('test/decoy/*.jpeg')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SuJ9U-W1vGh",
        "colab_type": "text"
      },
      "source": [
        "##Deliverable 1: Display the first image in each of the four sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHTnL0r_34Jn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ruw5ut92JoTp",
        "colab_type": "text"
      },
      "source": [
        "# Step 2: Load the original ImageNet-trained Inception v3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKqBQblXJsfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "# load model\n",
        "\n",
        "# Display a summary of the model structure:\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhT_kBUtlbxV",
        "colab_type": "text"
      },
      "source": [
        "## Deliverable 2: Number of parameters in layer 'conv2d_1 (Conv2D)'\n",
        "\n",
        "The conv2d_1 (Conv2D) layer has XXX parameters\n",
        "\n",
        "*Optional*: Each filter is..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H5uGDcxUlP4G"
      },
      "source": [
        "# Step 3: Test the original ImageNet-trained Inception v3 on our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZQU2v57plNVC",
        "colab": {}
      },
      "source": [
        "from keras.applications.inception_v3 import decode_predictions, preprocess_input\n",
        "import numpy as np\n",
        "from keras.preprocessing import image as kp_image\n",
        "\n",
        "WIDTH = 299\n",
        "HEIGHT = 299\n",
        "\n",
        "def predictImgNet(model, img):\n",
        "    \"\"\"Run model prediction on an image and decode predictions into 1000 ImageNet classes\n",
        "    Args:\n",
        "        model: keras model\n",
        "        img: PIL format image\n",
        "    Returns:\n",
        "        list of predicted labels and their probabilities \n",
        "    \"\"\"\n",
        "    x = kp_image.img_to_array(img)  # Convert image to nparray\n",
        "    x = np.expand_dims(x, axis=0)   # Need to pre-pend a dimension to indicate batch number.\n",
        "    x = preprocess_input(x)         # Normalize image to match how Inceptionv3 expects to receive images\n",
        "    preds = model.predict(x)        # Use the model to compute prediction score for each possible class\n",
        "    labels = decode_predictions(preds) # Decodes the output classes back to the original labels for the 1000 ImageNet classes\n",
        "    return labels[0]\n",
        "\n",
        "# Clasify 'train/trump/100.jpeg'\n",
        "\n",
        "# Classify 'test/decoy/28.jpeg'\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRDGWBFAxmO6",
        "colab_type": "text"
      },
      "source": [
        "## Deliverable 3: What are the top-ranked predictions  and their scores from the InceptionV3 original model for these two images? \n",
        "- for train/trump/100.jpeg...\n",
        "- for test/decoy/28.jpeg... "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iXYo_-O5MpN",
        "colab_type": "text"
      },
      "source": [
        "#Step 4: Transfer Learning. Reload the InceptionV3 CNN, but with a new dense layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqhpmAXHz7l1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "\n",
        "CLASSES = 2\n",
        "    \n",
        "# Load base model, but ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8B6MQPn_-v63",
        "colab_type": "text"
      },
      "source": [
        "##Deliverable 4: Examine the layers in the full model (see Step 2) and the new modified model using summary(). Which layer has the largest difference in the number of learnable parameters, when comparing the two models? What type of layer is it and why did the number of learnable parameters change?\n",
        "\n",
        "The ??? layer changes the most. It is reduced from ??? down to ??? because ???."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IadgsHtw48Of",
        "colab_type": "text"
      },
      "source": [
        "#Step 5: Create training and validation image generators to augment image sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFXIq_eT5QhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "WIDTH = 299\n",
        "HEIGHT = 299\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# data prep\n",
        "train_datagen = ImageDataGenerator(\n",
        "...\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "...\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "...\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obgVZFdM8hMy",
        "colab_type": "text"
      },
      "source": [
        "##Deliverable 5: Invoke “next” on your training ImageDataGenerator  to create a batch of 32 images and labels (where each label is a tuple). Create a 4rowx8col subplot matrix showing all 32 images. Each image should be titled with its label tuple."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxEdjtfR6rZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXByUzJPmYRJ",
        "colab_type": "text"
      },
      "source": [
        "#Step 6: Use transfer learning to train the new CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UIMyZkReKQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = ...\n",
        "BATCH_SIZE = ...\n",
        "STEPS_PER_EPOCH = ....\n",
        "VALIDATION_STEPS = ...\n",
        "\n",
        "MODEL_FILE = 'filename.model'\n",
        "\n",
        "history = model.fit_generator(\n",
        "...\n",
        "  \n",
        "model.save(MODEL_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Tf9ghMJGyBV",
        "colab_type": "text"
      },
      "source": [
        "##Deliverable 6: Plot the training and validation loss at each training epoch (i.e. the learning curve). Repeat for accuracy instead of loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mi_PZoqC5hh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_training(history):\n",
        "  acc = history.history['acc']\n",
        "  val_acc = history.history['val_acc']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "  epochs = range(len(acc))\n",
        "  \n",
        "  plt.plot(epochs, acc, 'r.')\n",
        "  plt.plot(epochs, val_acc, 'r')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  \n",
        "  plt.figure()\n",
        "  plt.plot(epochs, loss, 'r.')\n",
        "  plt.plot(epochs, val_loss, 'r-')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.show()\n",
        "  \n",
        "plot_training(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbgT-7755kUy",
        "colab_type": "text"
      },
      "source": [
        "#Step 7: Test the new CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtqGQesd6ytD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model(MODEL_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l-5t8d2Xsge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.inception_v3 import decode_predictions, preprocess_input\n",
        "import numpy as np\n",
        "from keras.preprocessing import image as kp_image\n",
        "\n",
        "HEIGHT = 299\n",
        "WIDTH = 299\n",
        "\n",
        "def predictTrump(model, img):\n",
        "    \"\"\"Run model prediction on an image and decode predictions into 1000 ImageNet classes\n",
        "    Args:\n",
        "        model: keras model\n",
        "        img: PIL format image\n",
        "    Returns:\n",
        "        Class label with higher predicted probabilities \n",
        "    \"\"\"\n",
        "    x = kp_image.img_to_array(img)  # Convert image to nparray\n",
        "    x = np.expand_dims(x, axis=0)   # Need to pre-pend a dimension to indicate batch number.\n",
        "    x = preprocess_input(x)         # Normalize image to match how Inceptionv3 expects to receive images\n",
        "    preds = model.predict(x)        # Use the model to compute prediction score for each possible class\n",
        "    label = 'trump' if preds[0][1]>preds[0][0] else 'decoy' # Decodes the predicted class scores to assign a single class label\n",
        "    return label\n",
        "\n",
        "# Example code showing how to predict a single image label:\n",
        "img = kp_image.load_img('test/decoy/28.jpeg', target_size=(HEIGHT, WIDTH))\n",
        "label = predictTrump(model, img)\n",
        "\n",
        "..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFuh44eXV5M_",
        "colab_type": "text"
      },
      "source": [
        "##Deliverable 7: Print confusion matrix and accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZDRNC9RWAQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt     \n",
        "\n",
        "# Function to pretty-print confusion matrix. Doesn't work perfectly...\n",
        "def printCM(cm,labels):\n",
        "  ax= plt.subplot()\n",
        "  sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
        "\n",
        "  # labels, title and ticks\n",
        "  ax.set_xlabel('Predicted labels')\n",
        "  ax.set_ylabel('True labels'); \n",
        "  ax.set_title('Confusion Matrix') \n",
        "  ax.xaxis.set_ticklabels(labels)\n",
        "  ax.yaxis.set_ticklabels(labels)\n",
        "  return\n",
        "\n",
        "labels = ['decoy', 'trump']\n",
        "cm = ..."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}